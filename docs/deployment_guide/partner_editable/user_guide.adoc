== User Guide

The following sections detail how to get started using the solution once the post deployment steps have been completed.

=== Hydrate your data lake with Jupyter notebooks

If your AMC S3 bucket already contained data before deployment of this solution, it will not be picked up automatically by the data lake. Only workflows run after deployment will trigger this process.

To hydrate the data lake and begin populating it with data from your AMC instance, follow these steps. When you’re finished, business stakeholders can use Amazon Athena to access the data returned from the workflow execution.

1. Sign in to the AWS Management Console, and open the Amazon SageMaker console.

2. On the left side of your screen, choose *Notebook* -> *Notebook Instances* (You should see one notebook named aws-quickstart-platform-manager-notebooks with status *In Service*. The prefix 'aws' may differ depending on the value set in the ddk.json file).

3. Click "Open JupyterLab" to open the Notebook Instance in a new tab

4. Open 'Getting_Started_With_AMC_Quickstart.ipynb' or refer to the README.md for  information on the additional notebooks contained.

This 'Getting Started' notebook covers the following:

* _Insert TPS Records_: To initialize the process of onboarding your AMC instance on the Amazon AD Tech platform, this notebook will walk through the steps to adds client configurations to a TPS Customer Configuration table in Amazon DynamoDB. The configuration includes your AMC Endpoint URL, AMC Bucket Name and other related information on your AMC Instance. The Tenant Provisioning Service (TPS) will then automatically:

** Onboard clients using configuration which is persisted in a DynamoDB Table. It helps to reduce time to onboard new customers

** Provide a centralized location to manage various clients and modules and supports multi-tenancy

* _Create Workflows_: To initialize the creation, scheduling and execution of AMC workflows, this notebook will walk through the steps to add a workflow to an AMC Workflows table in Amazon DynamoDB. From there you will also invoke this workflow to execute and populate data from your AMC Instance to your AMC S3 Bucket. WFM also allows you to:

** Automatically trigger the deployment of the SQS queues, IAM policies, workflows and workflow schedules in WFM for the customer’s AMC instance upon adding or updating a customer record to the Tenant Provisioning Service (TPS)

** Synchronize workflows and workflow schedules in the Workflow Library service with multiple AMC Instances

** Send execution requests to an SQS queue rather than directly to the AMC endpoint to prevents timeout failures when there are large number of requests in a short period of time

** Schedule with dynamic relative time windows rather than using AMC’s scheduling feature which only allows predefined scheduled reporting such as Daily or Weekly

** Track the status of all workflow executions for customer AMC instances whether they are submitted through WFM or other means (postman, etc.). Having the status synced to DynamoDB allows events to be triggered or notifications to be sent when executions change state. This table can also be used to track historical executions for troubleshooting or performance monitoring.

Once you have hydrated the data lake by running workflows, the data will populate in the *stage* S3 bucket under the *post-stage* prefix.

=== Query data with Athena

If this is your first time using Athena on this AWS account then you must set the query result location in S3 by following the below steps.

.. Navigate to the Athena console.
.. From the top menu click on *Settings*.
.. Click *Manage*.
.. Click *Browse S3* next to the first open field.
.. Find the deployed S3 bucket with the suffix '-athena' (Bucket name follows the same convention as the others deployed. Any custom bucket can be designated for this purpose, this one is simply deployed as part of the solution for ease).
.. Check off the bucket and click *Choose*.
.. *Save* the new settings.

You are now ready to start querying your tables with Athena.

=== Delete deployed resources when finished

When you're finished with the architecture deployed by this solution, delete the resources from your AWS account so that you're no longer charged for them. These resources include S3 buckets, AWS CloudFormation stacks, DDK bootstrap, CodeCommit repos, AWS Key Management Service (AWS KMS) keys, Lambda layers, and Amazon Simple Queue Service (Amazon SQS) queues and rules. To delete all these resources, follow these steps.

. Look into `Makefile`.
+
```
$ cd quickstart-amazon-marketing-cloud
$ cat MakeFile
```

. Verify that the following functions are passing the correct stack names.

* The `delete_repositories` function is passing `-d <AMC_REPO_NAME>` (default: `ddk-amc-quickstart`).
+
* The `delete_bootstrap` function is passing `--stack-name <BOOTSTRAP_STACK_NAME>` (default: `DdkDevBootstrap`).

. Enter the following command:
+
```
$ make delete_all
```

Some CloudWatch general log groups may remain in your account with logs specific to {partner-product-name} solution resources. Examples:

* `/aws/sagemaker/NotebookInstances`
* `/aws-glue/jobs/error`
* `/aws-glue/jobs/output`
